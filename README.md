![Architecture](docs/architecture.png)

<!-- Badges -->
![Python](https://img.shields.io/badge/Python-3.13-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.110.0-green)
![LangChain](https://img.shields.io/badge/LangChain-Orchestration-orange)
![Render](https://img.shields.io/badge/Deployed%20on-Render-purple)

<a href="https://context-aware-research-brief-generator-f2se.onrender.com/docs" target="_blank">
    <img src="https://img.shields.io/badge/View%20API%20Docs-Click%20Here-brightgreen?style=for-the-badge">
</a>

# ğŸš€ Objective & Problem Statement

**â“ Problem:**
Researchers spend a lot of time manually collecting, analyzing, and summarizing information. This is slow, inconsistent, and prone to bias.

**ğŸ’¡ Solution:**
An AI-powered research assistant that automatically creates **structured, evidence-linked research briefs**.
- ğŸ§© Uses **LangGraph** for workflow orchestration
- ğŸ¤– Uses **LangChain** for LLM and tool interaction
- ğŸ”„ Keeps context across sessions for follow-up questions

---

# âœ¨ Features
- ğŸ“„ Automated, structured research brief generation.
- ğŸ” Multi-source web search with fallback logic.
- ğŸ¤– Multi-model LLM orchestration using LangGraph + LangChain.
- ğŸ§  Session context retention for follow-up queries.
- ğŸ“Š Evidence-linked references with timestamps.

---

# ğŸ¯ Live Demo
Try it here: [**API Documentation on Render**](https://context-aware-research-brief-generator-f2se.onrender.com/docs)

---

# ğŸ› ï¸ How It Works (Workflow)

1. ğŸŸ¢ **Start Request**
2. ğŸ§  **Context Summarization** (only if follow-up)
3. ğŸ“ **Planning** (generate steps)
4. ğŸ” **Search** (multi-source with fallback between SerpAPI & DuckDuckGo)
5. ğŸ“„ **Content Fetching** (full text, skips if no results)
6. âœï¸ **Per-Source Summarization**
7. ğŸ—ï¸ **Synthesis** (final brief creation)
8. âœ… **Post-Processing** (validation & save)
9. ğŸ **End Result**

---

# âš™ï¸ Models & Tools

- âš¡ **Google Gemini 1.5 Flash** â€” Large context, fast, best for planning & synthesis
- ğŸ§  **OpenAI GPT-3.5-Turbo** â€” Fallback, faster for summarization
- ğŸ–¥ï¸ **Ollama (local)** â€” Unlimited use for offline dev
- ğŸ” **Search** â€” SerpAPI (free tier) + DuckDuckGo (free fallback)

---

# ğŸ—‚ï¸ Data Models (Pydantic Validation)

- **BriefRequest:** topic, depth, follow_up, user_id
- **FinalBrief:** title, executive summary, key findings, detailed analysis, implications, limitations, references, metadata

---

# ğŸƒ How to Run

**Local:**
```bash
git clone <repo-url>
cd <repo>
pip install -r requirements.txt

# Add .env file:
GOOGLE_API_KEY=...
OPENAI_API_KEY=...
SERPAPI_API_KEY=...
LANGCHAIN_API_KEY=...

uvicorn app.api:app --reload
```

Access: [http://127.0.0.1:8000](http://127.0.0.1:8000)

**Deploy on Render:**
- Service: Web Service
- Build: `pip install -r requirements.txt`
- Start: `gunicorn -w 4 -k uvicorn.workers.UvicornWorker app.api:app`
- Env Vars: Add same keys in Render settings

---

# ğŸ“¬ API Example

**POST /brief**
```json
{
  "topic": "Impact of AI on education",
  "depth": 2,
  "follow_up": false,
  "user_id": "test-user-1"
}
```

**Example Output**
```json
{
  "title": "Research Brief: Impact of AI on education",
  "executive_summary": "Synthesis failed.",
  "key_findings": [],
  "detailed_analysis": "",
  "implications": "",
  "limitations": "",
  "references": [
    {
      "title": "Error",
      "url": "",
      "access_date": "2025-08-14T18:07:38.947329",
      "relevance_note": "Synthesis failed"
    }
  ],
  "metadata": {
    "creation_timestamp": "2025-08-14T18:07:38.952476",
    "research_duration": 47,
    "total_sources_found": 5,
    "sources_used": 5,
    "confidence_score": 0.1,
    "depth_level": 2,
    "token_usage": {}
  }
}
```

---

# ğŸ›  Tech Stack
- **Backend:** FastAPI, Python 3.13
- **AI Orchestration:** LangGraph, LangChain
- **LLMs:** Google Gemini 1.5 Flash, OpenAI GPT-3.5 Turbo, Ollama
- **Search APIs:** SerpAPI, DuckDuckGo
- **Database:** SQLite (SQLAlchemy ORM)
- **Deployment:** Render

---

# ğŸ›¡ï¸ Error Handling
- Fallback from Gemini â†’ GPT-3.5 in case of API rate limit errors.
- Graceful degradation: returns structured error messages with metadata.

---

# ğŸ’¸ Cost & Performance
- **Cost:** $0 (free tiers)
- **Latency:** 60â€“90 sec per request (may increase with API rate limits)

---

# ğŸš§ Current Limitations & Future Plans
**Limitations:**
- â³ Free-tier API rate limits
- ğŸ” Search quality depends on public search engines
- ğŸš« Some sites block content fetching

**Future Improvements:**
- ğŸ“š Add academic databases (arXiv, Google Scholar)
- ğŸ•µï¸â€â™‚ï¸ Use headless browser for complex sites
- ğŸŒ Multi-language & translation support

---

# ğŸ‘¨â€ğŸ’» Author
Developed by **Lakshmi Nivas**  
GitHub: [45nivas](https://github.com/45nivas)
